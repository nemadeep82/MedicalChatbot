{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as lcpinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"d18ddb58-7c71-4208-8072-2dda5ed47ef4\"\n",
    "PINECONE_API_ENV = \"aws-starter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(datadir):\n",
    "    loader = DirectoryLoader(datadir,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrated_docs = load_documents(\"C:\\genaipjts\\medicalchatbot\\MedicalChatbot\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"C:/genaipjts/medicalchatbot/MedicalChatbot/data/\")\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def split_chunks(docList):\n",
    "    print(\"inside split_chunks func : \",len(docList))\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(docList)\n",
    "    print(\"inside split_chunks func after chubking: \",len(text_chunks))\n",
    "    return text_chunks\n",
    "\"\"\"\n",
    "\n",
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_huggingface_embeddings_obj():\n",
    "    emdObj = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return emdObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingObj = ret_huggingface_embeddings_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enbdQr = embeddingObj.embed_query(\"My name is Deepak Nema\")\n",
    "print(len(enbdQr))\n",
    "enbdQr\n",
    "\n",
    "#query_result = embeddingObj.embed_query(\"My name is Deepak Nema\")\n",
    "#print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working\n",
    "\n",
    "from pinecone import Pinecone as pcclass, ServerlessSpec\n",
    "\n",
    "#api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "# configure client\n",
    "pc = pcclass(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name=\"medical-chatbot\"\n",
    "\n",
    "#pc.from_texts()\n",
    "\n",
    "docsearch=lcpinecone.from_texts([t.page_content for t in text_chunks], embeddingObj, index_name=index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "  pinecone-client[grpc]==3.0.0 \\\n",
    "  pinecone-datasets==0.7.0 \\\n",
    "  langchain-pinecone==0.0.3 \\\n",
    "  langchain-openai==0.0.7 \\\n",
    "  langchain==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working\n",
    "# Need not run again. Index exists in pinecone\n",
    "\n",
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "#os.environ['OPENAI_API_KEY'] = '<YOUR_OPENAI_API_KEY>'\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    " \n",
    "# path to an example text file\n",
    "\n",
    "vectorstore_from_texts = PineconeVectorStore.from_texts(\n",
    "        [t.page_content for t in text_chunks],\n",
    "        index_name=index_name,\n",
    "        embedding=embeddingObj\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "vectorstore_from_texts=PineconeVectorStore.from_existing_index(index_name, embeddingObj)\n",
    "\n",
    "query = \"What are Allergies\"\n",
    "\n",
    "docs = vectorstore_from_texts.similarity_search(query=query)\n",
    "\n",
    "#docs=docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "print(PROMPT)\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"C:\\genaipjts\\medicalchatbot\\MedicalChatbot\\model\\llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "reteieverObj = vectorstore_from_texts.as_retriever(search_kwargs={'k': 2})\n",
    "#reteieverObj = vectorstore_from_texts.as_retriever()\n",
    "print(type(reteieverObj))\n",
    "\n",
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=reteieverObj,\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if required\n",
    "!pip install -qU langchain\n",
    "!pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_input=input(f\"Input Prompt:\")\n",
    "user_input = \"What are the colors of blood cells?\"\n",
    "result=qa({\"query\": user_input})\n",
    "print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
